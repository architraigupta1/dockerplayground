* Run an image (create + start + watch)
docker run <img_name>
docker run <img_name> <override_default_cmd>: This overrides the default command set for the container to execute on startup

* Create a container with the image
docker create hello-world

only created the container. Basically sets up the File system of the container

* Start a container with container id
docker start -a container_id
The start command can be used to re-run the previously stopped containers also. We cannot change the default command of previously run containers

-a: watch the running container and print the output if any
Without -a we run the container but do not see any output from it

* Print docker containers (since last cleanup)
docker ps: prints only the currently running containers
docker ps --all: prints all the containers that were ever create

* Delete old stopped containers, image cache (all the images will have to be downloaded again from the repo.)
docker system prune

* Retrieve logs from a running/stopped container

docker logs <container_id>: This command does not re-run an already stopped container. It just pulls the logs from it.

* Stop a running container

docker stop <container_id>: sends a SIGTERM signal to the running process in the container. The process can the release resources, perform clean up and then shut down gracefully

* Kill a running container

docker kill <container_id>: sends a SIGKILL signal to the running process in the container and asks to shutdowm immediately without any grace period.
docker stop command also waits for 10s for the container to stop and otherwise automatically send a SIGKILL signal forcefully shutting down the container.

* Execute a command in a running container
docker exec -it <container_id> <command>
docker exec -it 23df353fabc redis-cli
docker exex -it 23df353fabc sh: opens up shell which can then be used to perform any other command inside the container

without -it flags the command simply starts and stops redis-cli and exits
-it flag is important
Linux processes have 3 communication channels: STDIN, STDOUT, STDERR. STDIN provides input to the program and STDOUT, STDERR are for the output.
-i flag ensures that whatever user submits send it to the STDIN of redis-cli program
-t among other things formats the input/output nicely.

* Build a dockerfile / new docker image from a docker file
docker build .
pass the current context to the cli which then forwards it to the docker server which builds the image step by step.

At every step, an temporary intermediate container is spinned up based on the last step, the current step is applied on top of it and then the temporary intermediate container is deleted. A snapshot of file system of the intermediate container is taken and an intermediate image is built.

When the same docker file (with some changes) is used built again, then for all the steps before the first line change docker uses the cache and does not do any computing because of this the image building process is very fast.

* Build a container from a custom docker file

docker build -f <filename> .
docker build -f archit.dev .

* Tag a docker image

docker build -t <docker_id>/<project_name>:<version>
docker build -t architraigupta/redis:latest

It allows to create and start a container by using the tag (human readable) instead of an image_id.
If you want to use the latest version of the image then no need to provide the version in the run command

docker run architraigupta/redis:latest is same as docker run architraigupta/redis

* Create an image from a running docker container

docker commit -c 'CMD ["redis-server"]' <container_id>

This allows to create an image out of a running container which can then be used to run new containers anytime.
Basically, spin up a container, makes changes to its file system and then commit it as an image so that it can be reused.
This is used rarely.

* Copy files from local hard drive to the container

COPY local_machine_path path_to_copy_on_container

local_machine_path is relatvie to the build context (the folder where we have the Dockerfile)

* Forward requests on local machine / network to the container

Container has it's own set of ports and any request coming to the machine is not automatically forwarded to the container. The container port mapping has to be explicitly specified while running the container. It cannot be set in the Dockerfile. Also, the container has no issues while reaching the outside world, only for incoming requests the mapping has to be done.

docker run -p <port on local machine> : <port on container> <image_id / image_name>
docker run -p 8080:8080 architraigupta/simplewebapp

* Change working directory

WORKDIR /usr/app

This creates a new directory if it does not exist and then changes the working directory to the specified directory for all future commands as well.


* alpine is a conventionally famous word in Docker world to represent the most stipped down version of an image. The image will have a version alpine to indicate that it just contains bare minimum things.


* Share local volume/directory with container
docker run -v local_directory:container_dir <image_id>
docker run -v $(pwd):/app arcgupta/demoapp

If we want to make sure that sharing the local directory does not override any directory on the container then we can bookmark it.
docker run -v container_dir <image_id>
docker run -v /app/node_modules arcgupta/demoapp

=========================================DOCKER COMPOSE========================================================

- Managing multiple containers using plain vanila docker cli is cumbersome.
- Docker compose helps us managing multiple containers via a docker-compose.yml file.
- It gets automatically installed along with docker.
- docker-compose has cli commands very similar to the docker cli
- All docker-compose commands must be issued only from the directory containing docker-compose.yml file else we get error.
- The only mandatory statement in the yml file is version: 3
- Specify all the containers in services
- Specify the port mapping like ports: -"4001:8081"
- You can build containers either from images or from Dockerfile.
- docker-compose up: start all the containers
- docker-compose down: stop all the containers
- docker-compose ps: status of all the containers
- docker-compose up --build: (re)build the images and then start the docker containers




